---
title: Batch Operations
description: Efficient bulk vector operations
author: zoobzio
published: 2025-12-30
updated: 2025-12-30
tags:
  - Cookbook
  - Batch
  - Upsert
  - Performance
---

# Batch Operations

This cookbook covers efficient patterns for bulk vector operations.

## Batch Upsert

### Single Record

```go
record := vectql.NewRecord(v.P("id"), vectql.Vec(v.P("embedding"))).
    WithMetadata(v.M("products", "name"), v.P("name")).
    WithMetadata(v.M("products", "category"), v.P("category")).
    Build()

result, err := vectql.Upsert(v.C("products")).
    AddVector(record).
    Render(pinecone.New())
```

### Multiple Records

```go
func BatchUpsert(v *vectql.VECTQL, count int) (*vectql.QueryResult, error) {
    builder := vectql.Upsert(v.C("products"))

    for i := 0; i < count; i++ {
        record := vectql.NewRecord(
            v.P(fmt.Sprintf("id_%d", i)),
            vectql.Vec(v.P(fmt.Sprintf("vec_%d", i))),
        ).
            WithMetadata(v.M("products", "name"), v.P(fmt.Sprintf("name_%d", i))).
            WithMetadata(v.M("products", "category"), v.P(fmt.Sprintf("cat_%d", i))).
            Build()

        builder = builder.AddVector(record)
    }

    return builder.Render(pinecone.New())
}
```

### Using Vectors Method

```go
func BulkUpsert(v *vectql.VECTQL, records []vectql.VectorRecord) (*vectql.QueryResult, error) {
    return vectql.Upsert(v.C("products")).
        Vectors(records).
        Namespace(v.P("namespace")).
        Render(pinecone.New())
}
```

## Batch Delete

### Delete by IDs

```go
func BatchDelete(v *vectql.VECTQL) (*vectql.QueryResult, error) {
    return vectql.Delete(v.C("products")).
        IDs(v.P("ids")). // Array of IDs
        Render(pinecone.New())
}
```

### Delete by Filter

```go
func DeleteByCategory(v *vectql.VECTQL) (*vectql.QueryResult, error) {
    return vectql.Delete(v.C("products")).
        Filter(v.Eq(v.M("products", "category"), v.P("category"))).
        Render(pinecone.New())
}

func DeleteInactive(v *vectql.VECTQL) (*vectql.QueryResult, error) {
    return vectql.Delete(v.C("products")).
        Filter(v.Eq(v.M("products", "active"), v.P("active"))). // active = false
        Render(pinecone.New())
}
```

### Delete All in Namespace

```go
func ClearNamespace(v *vectql.VECTQL) (*vectql.QueryResult, error) {
    return vectql.Delete(v.C("products")).
        DeleteAll(true).
        Namespace(v.P("namespace")).
        Render(pinecone.New())
}
```

## Batch Fetch

```go
func BatchFetch(v *vectql.VECTQL) (*vectql.QueryResult, error) {
    return vectql.Fetch(v.C("products")).
        IDs(v.P("ids")). // Array of IDs
        Namespace(v.P("namespace")).
        Render(pinecone.New())
}
```

## Chunked Processing

For very large batches, process in chunks:

```go
type BatchProcessor struct {
    instance  *vectql.VECTQL
    renderer  vectql.Renderer
    batchSize int
}

func (p *BatchProcessor) ProcessRecords(records []Record) error {
    for i := 0; i < len(records); i += p.batchSize {
        end := i + p.batchSize
        if end > len(records) {
            end = len(records)
        }

        chunk := records[i:end]
        if err := p.upsertChunk(chunk); err != nil {
            return fmt.Errorf("failed at chunk %d: %w", i/p.batchSize, err)
        }
    }
    return nil
}

func (p *BatchProcessor) upsertChunk(records []Record) error {
    builder := vectql.Upsert(p.instance.C("products"))

    for idx, r := range records {
        record := vectql.NewRecord(
            p.instance.P(fmt.Sprintf("id_%d", idx)),
            vectql.Vec(p.instance.P(fmt.Sprintf("vec_%d", idx))),
        ).Build()
        builder = builder.AddVector(record)
    }

    _, err := builder.Render(p.renderer)
    return err
}
```

## Namespace Operations

### Upsert with Namespace

```go
func UpsertToNamespace(v *vectql.VECTQL, tenantID string) (*vectql.QueryResult, error) {
    record := vectql.NewRecord(v.P("id"), vectql.Vec(v.P("vec"))).
        WithMetadata(v.M("products", "name"), v.P("name")).
        Build()

    return vectql.Upsert(v.C("products")).
        AddVector(record).
        Namespace(v.P("namespace")).
        Render(pinecone.New())
}
```

### Delete Namespace

```go
func DeleteNamespace(v *vectql.VECTQL) (*vectql.QueryResult, error) {
    return vectql.Delete(v.C("products")).
        DeleteAll(true).
        Namespace(v.P("namespace")).
        Render(pinecone.New())
}
```

## Update Metadata

### Update Single Field

```go
func UpdateCategory(v *vectql.VECTQL) (*vectql.QueryResult, error) {
    return vectql.Update(v.C("products")).
        IDs(v.P("ids")).
        SetMetadata(v.M("products", "category"), v.P("new_category")).
        Render(pinecone.New())
}
```

### Update Multiple Fields

```go
func UpdateProduct(v *vectql.VECTQL) (*vectql.QueryResult, error) {
    return vectql.Update(v.C("products")).
        IDs(v.P("ids")).
        SetMetadata(v.M("products", "name"), v.P("name")).
        SetMetadata(v.M("products", "price"), v.P("price")).
        SetMetadata(v.M("products", "active"), v.P("active")).
        Render(pinecone.New())
}
```

## Error Handling

```go
func SafeBatchUpsert(v *vectql.VECTQL, records []Record) error {
    const maxRetries = 3
    const batchSize = 100

    for i := 0; i < len(records); i += batchSize {
        end := i + batchSize
        if end > len(records) {
            end = len(records)
        }

        chunk := records[i:end]

        var lastErr error
        for attempt := 0; attempt < maxRetries; attempt++ {
            result, err := upsertBatch(v, chunk)
            if err == nil {
                break
            }
            lastErr = err
            time.Sleep(time.Duration(attempt+1) * time.Second)
        }

        if lastErr != nil {
            return fmt.Errorf("batch %d failed after %d retries: %w",
                i/batchSize, maxRetries, lastErr)
        }
    }

    return nil
}
```

## Provider Limits

| Provider | Max Batch Size | Max Vector Dimensions |
|----------|----------------|----------------------|
| Pinecone | 100 | 20,000 |
| Qdrant | 100 | Unlimited |
| Milvus | 1000 | 32,768 |
| Weaviate | 100 | 65,535 |

## Best Practices

1. **Respect batch limits** - Don't exceed provider maximums
2. **Use chunking** - Process large datasets in manageable pieces
3. **Implement retries** - Handle transient failures gracefully
4. **Use namespaces** - Organize data for efficient operations
5. **Monitor progress** - Log batch progress for debugging
6. **Validate before upsert** - Check vector dimensions and metadata types
