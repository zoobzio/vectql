---
title: Hybrid Search
description: Storing dense and sparse vectors for hybrid retrieval
author: zoobzio
published: 2025-12-30
updated: 2025-12-30
tags:
  - Guide
  - Hybrid Search
  - Sparse Vectors
---

# Hybrid Search

Hybrid search combines dense semantic vectors with sparse keyword vectors for improved retrieval quality. VECTQL supports storing both vector types for providers that offer hybrid search capabilities.

## Overview

| Vector Type | Best For | Example |
|-------------|----------|---------|
| Dense | Semantic similarity | "comfortable seating" → finds "ergonomic chairs" |
| Sparse | Keyword matching | "model XR-500" → finds exact product |
| Hybrid | Both | Combines semantic understanding with keyword precision |

## Schema Setup

Define both dense and sparse embeddings in your VDML schema:

```go
products := vdml.NewCollection("products").
    AddEmbedding(
        vdml.NewEmbedding("dense_embedding", 1536).
            WithMetric(vdml.Cosine),
    ).
    AddEmbedding(
        vdml.NewEmbedding("sparse_embedding", 30000),
    )
```

## Storing Hybrid Vectors

Include both dense and sparse vectors when upserting records:

```go
record := vectql.NewRecord(v.P("id"), vectql.Vec(v.P("dense_vec"))).
    WithSparseVector(vectql.SparseVec(v.P("sparse_vec"))).
    WithMetadata(v.M("products", "name"), v.P("name")).
    WithMetadata(v.M("products", "category"), v.P("category"))

result, err := vectql.Upsert(v.C("products")).
    AddVector(record.Build()).
    Render(pinecone.New())
```

## Sparse Vector Format

Sparse vectors are represented as index-value pairs. Use `SparseVecLiteral` for literal values or `SparseVec` for parameterized values:

```go
// Literal sparse vector from BM25 or SPLADE
sparseIndices := []int{42, 1337, 9001}      // Token indices
sparseValues := []float32{0.8, 0.5, 0.3}    // Token weights

sparse := vectql.SparseVecLiteral(sparseIndices, sparseValues)

// Or parameterized
sparse := vectql.SparseVec(v.P("sparse_vec"))
```

## Provider Support

| Feature | Pinecone | Qdrant | Milvus | Weaviate |
|---------|----------|--------|--------|----------|
| Dense vectors | Yes | Yes | Yes | Yes |
| Sparse vectors | Yes | Yes | Yes | Yes |
| Hybrid storage | Yes | Yes | Yes | Yes |
| Hybrid query | Provider SDK | Provider SDK | Provider SDK | Provider SDK |

**Note:** Query-time hybrid search with alpha weighting is handled by provider SDKs. VECTQL generates the query structure; consult your provider's documentation for runtime hybrid search configuration.

## Batch Upsert with Hybrid Vectors

```go
func UpsertHybridBatch(v *vectql.VECTQL, count int) (*vectql.QueryResult, error) {
    builder := vectql.Upsert(v.C("products"))

    for i := 0; i < count; i++ {
        record := vectql.NewRecord(
            v.P(fmt.Sprintf("id_%d", i)),
            vectql.Vec(v.P(fmt.Sprintf("dense_%d", i))),
        ).
            WithSparseVector(vectql.SparseVec(v.P(fmt.Sprintf("sparse_%d", i)))).
            WithMetadata(v.M("products", "name"), v.P(fmt.Sprintf("name_%d", i))).
            Build()

        builder = builder.AddVector(record)
    }

    return builder.Render(pinecone.New())
}
```

## Searching Hybrid Data

Search queries target the dense embedding. Provider-level hybrid search configuration (alpha weighting) is handled at runtime:

```go
// Search using dense vectors - provider handles hybrid ranking
result, err := vectql.Search(v.C("products")).
    Vector(vectql.Vec(v.P("query_vec"))).
    Embedding(v.E("products", "dense_embedding")).
    TopK(20).
    Filter(v.Eq(v.M("products", "in_stock"), v.P("in_stock"))).
    Render(pinecone.New())
```

## Generating Sparse Vectors

Common approaches for generating sparse vectors:

### BM25

Traditional keyword scoring:

```go
// Use a BM25 library to generate sparse vectors
// indices = token IDs from vocabulary
// values = BM25 scores
```

### SPLADE

Learned sparse representations:

```go
// Use SPLADE model to generate sparse vectors
// Provides better semantic coverage than BM25
```

### TF-IDF

Term frequency-inverse document frequency:

```go
// indices = vocabulary indices
// values = TF-IDF scores
```

## Best Practices

1. **Use the same tokenizer** for indexing and querying sparse vectors
2. **Normalize sparse values** if using different sparse encoders
3. **Store both vector types** to enable provider-level hybrid search
4. **Consult provider docs** for runtime alpha weighting configuration
5. **Monitor latency** - hybrid search may be slower than single-vector search
